# ğŸš€ DAB Evaluation - PyPI Release Guide

## ğŸ“¦ Package Information

- **Package Name**: `dab-evaluation`
- **Version**: `1.0.0`
- **Description**: DAB Evaluation SDK - Web3 Agent Evaluation Framework
- **License**: MIT

## ğŸ› ï¸ Prerequisites

1. **PyPI Account**: Create account at [PyPI](https://pypi.org/account/register/)
2. **TestPyPI Account**: Create account at [TestPyPI](https://test.pypi.org/account/register/)
3. **API Token**: Generate API token from PyPI account settings

## ğŸ“‹ Quick Release Steps

### 1. Install Build Tools
```bash
pip install build twine
```

### 2. Build Package
```bash
# Clean previous builds
rm -rf build/ dist/ *.egg-info/

# Build package
python -m build

# Check build
twine check dist/*
```

### 3. Upload to TestPyPI (Recommended First)
```bash
# Upload to test PyPI
twine upload --repository testpypi dist/*

# Test install from test PyPI
pip install -i https://test.pypi.org/simple/ dab-evaluation
```

### 4. Upload to Production PyPI
```bash
# Upload to production PyPI
twine upload dist/*
```

## ğŸ§ª Testing Installation

After uploading, test the installation:

```bash
# Install from PyPI
pip install dab-evaluation

# Test import
python -c "import dab_eval; print(dab_eval.__version__)"
```

## ğŸ“ Package Structure

```
dab-evaluation/
â”œâ”€â”€ dab_eval/                    # Main package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dab_eval.py             # Core evaluation logic
â”‚   â””â”€â”€ evaluation/              # Evaluation modules
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_evaluator.py
â”‚       â”œâ”€â”€ llm_evaluator.py
â”‚       â””â”€â”€ hybrid_evaluator.py
â”œâ”€â”€ data/                       # Sample data
â”‚   â””â”€â”€ benchmark.csv
â”œâ”€â”€ examples/                   # Usage examples
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â””â”€â”€ batch_evaluation.py
â”œâ”€â”€ setup.py                   # Setup configuration
â”œâ”€â”€ pyproject.toml             # Modern Python packaging
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md                  # Documentation
â”œâ”€â”€ LICENSE                    # MIT License
â””â”€â”€ MANIFEST.in               # Package manifest
```

## ğŸ¯ Usage After Installation

```python
import asyncio
from dab_eval import DABEvaluator, AgentMetadata, TaskCategory

async def main():
    # LLM configuration
    llm_config = {
        "model": "gpt-4",
        "base_url": "https://api.openai.com/v1",
        "api_key": "your-api-key",
        "temperature": 0.3,
        "max_tokens": 2000
    }
    
    # Create evaluator
    evaluator = DABEvaluator(llm_config, "output")
    
    # Define agent
    agent = AgentMetadata(
        url="http://localhost:8000",
        capabilities=[TaskCategory.WEB_RETRIEVAL],
        timeout=30
    )
    
    # Evaluate agent
    result = await evaluator.evaluate_agent(
        question="What is the date when Bitcoin was created?",
        agent_metadata=agent,
        category=TaskCategory.WEB_RETRIEVAL,
        expected_answer="2009-01-03"
    )
    
    print(f"Score: {result.evaluation_score}")

if __name__ == "__main__":
    asyncio.run(main())
```

## ğŸ”§ Troubleshooting

### Common Issues

1. **"Package already exists"**: Increment version number in `setup.py` and `pyproject.toml`
2. **"Invalid distribution"**: Check `MANIFEST.in` and ensure all files are included
3. **"Missing dependencies"**: Update `requirements.txt` and `pyproject.toml`

### Version Management

- Update version in both `setup.py` and `pyproject.toml`
- Use semantic versioning (e.g., 1.0.0, 1.0.1, 1.1.0)
- Tag releases in git: `git tag v1.0.0 && git push origin v1.0.0`

## ğŸ“Š Build Status

âœ… **Build Successful**: Package builds without errors  
âœ… **Dependencies**: All required dependencies included  
âœ… **Structure**: Proper Python package structure  
âœ… **Manifest**: All necessary files included  

## ğŸ‰ Ready for Release!

The package is ready to be published to PyPI. Follow the steps above to upload to TestPyPI first, then to production PyPI.
